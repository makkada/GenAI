pip3 install virtualenv 
virtualenv my_env # create a virtual environment my_env
source my_env/bin/activate # activate my_env

python3 -m pip install transformers==4.30.2 torch

Tokens in NLP are individual units or elements that text or sentences are divided into. Tokenization or vectorization is the process of converting tokens into numerical representations. In NLP tasks, you often use the encode_plus method from the tokenizer object to perform tokenization and vectorization.
